# Face Embeddings Visualizer - User Guide

Welcome to the Face Embeddings Visualizer! This interactive tool uses t-SNE to visualize high-dimensional face embeddings in 2D space, making it easy to explore relationships between faces, identify clusters, and organize your face data.

## üöÄ Quick Start

1. **Start the server** (if not already running):
   ```bash
   npm run serve
   ```

2. **Open the visualizer** in your browser:
   ```
   http://localhost:8080/example/face-embeddings-demo.html
   ```

3. **Load your data** or generate sample data to explore the features!

---

## üìä Understanding Face Embeddings

**What are face embeddings?**
- Face embeddings are numerical vectors (typically 128, 256, or 512 dimensions) that represent a face
- Generated by face recognition models like FaceNet, ArcFace, or DeepFace
- Similar faces have similar embedding vectors (small distance in embedding space)

**Why visualize them?**
- See which faces are similar to each other
- Identify natural groupings (family members, departments, etc.)
- Detect outliers or misclassified faces
- Understand the structure of your face dataset

---

## üìÅ Data Format

### Required JSON Structure

Your data file should be a JSON object with the following structure:

```json
{
  "embeddings": [
    [0.123, -0.456, 0.789, ...],  // Face 1: array of N numbers (e.g., 128D)
    [0.234, -0.567, 0.890, ...],  // Face 2: array of N numbers
    // ... more faces
  ],
  "images": [
    "data:image/jpeg;base64,/9j/4AAQSkZJRg...",  // Base64 encoded image
    "https://example.com/face1.jpg",              // Or image URL
    // ... one image per embedding
  ],
  "labels": [
    "John Smith",      // Face 1 name/label
    "Jane Doe",        // Face 2 name/label
    // ... one label per embedding
  ],
  "metadata": {
    "description": "Optional metadata",
    "embedding_model": "FaceNet",
    "embedding_dimension": 128,
    "created_date": "2024-01-01"
  }
}
```

### Field Descriptions

- **`embeddings`** (required): Array of face embedding vectors
  - Each embedding should be an array of numbers
  - All embeddings must have the same dimension
  - Example dimensions: 128 (FaceNet), 512 (ArcFace)

- **`images`** (optional but recommended): Array of face images
  - Can be base64-encoded data URIs: `"data:image/jpeg;base64,..."`
  - Can be URLs: `"https://example.com/face.jpg"`
  - Can be empty array `[]` if you only want to visualize points
  - Must match the order of embeddings

- **`labels`** (optional): Array of names/identifiers for each face
  - Strings describing each face (name, ID, etc.)
  - If omitted, faces will be labeled as "Face 1", "Face 2", etc.

- **`metadata`** (optional): Additional information about your dataset

### Example: Minimal Data File

```json
{
  "embeddings": [
    [0.1, 0.2, 0.3, 0.4, 0.5],
    [0.2, 0.3, 0.4, 0.5, 0.6],
    [0.9, 0.8, 0.7, 0.6, 0.5]
  ],
  "images": [],
  "labels": ["Person A", "Person B", "Person C"]
}
```

---

## üéÆ How to Use the Visualizer

### 1. Loading Data

**Option A: Upload Your Own Data**
- Click the upload area or drag-and-drop your JSON file
- The file will be validated and loaded automatically

**Option B: Generate Sample Data**
- Click "Generate Sample Data" to create test faces
- This creates 50 synthetic faces in 5 clusters with colorful placeholder images

### 2. Running t-SNE

Once data is loaded:

1. **Adjust parameters** (optional):
   - **Perplexity** (5-50): Balance between local and global structure
     - Lower values: Focus on local neighborhoods
     - Higher values: Preserve global structure
     - Rule of thumb: Set to 5-50, typically 30
   
   - **Learning Rate** (10-500): Optimization speed
     - Too low: Slow convergence
     - Too high: Unstable results
     - Typical value: 100-200
   
   - **Max Iterations** (100-1000): How long to optimize
     - More iterations = better quality (but slower)
     - Typical value: 300-500

2. **Click "Run t-SNE"** and wait for the algorithm to complete
   - You'll see real-time progress updates
   - The visualization updates every 10 iterations
   - Final result appears when complete

### 3. Interactive Features

#### üñ±Ô∏è **Hover over faces**
- Shows a tooltip with:
  - Face image preview
  - Label/name
  - 2D coordinates

#### üëÜ **Click on a face**
- Highlights the selected face (yellow border)
- Shows detailed information in the right panel:
  - Full-size face image
  - Label and coordinates
  - Current group assignment
- Displays **similar faces** based on embedding distance (not visual position)

#### üé® **Display Options**
- **Point Size**: Adjust the size of face circles
- **Show Labels**: Toggle name labels on/off
- **Show Connections**: Draw lines to nearest neighbors

---

## üë• Working with Groups

### Manual Grouping

1. **Create a group**:
   - Enter a name in "New group name" field
   - Click "‚ûï Add Group"
   - The group appears in the list with a unique color

2. **Assign faces to groups**:
   - Click on a face to select it
   - In the detail panel, use the "Assign to Group" dropdown
   - The face will be colored according to its group

3. **View group members**:
   - Click on a group in the list to highlight its members

### Auto-Detect Clusters

1. Click "ü§ñ Auto-Detect Clusters"
2. The algorithm automatically identifies natural groupings using k-means clustering
3. Groups are created and colored automatically
4. You can rename or modify these groups afterward

**When to use auto-clustering:**
- Initial exploration of unknown datasets
- Finding natural groupings before manual refinement
- Quality check after manual grouping

---

## üíæ Exporting Results

### Export as JSON
- Saves everything: embeddings, images, labels, t-SNE output, and groups
- Useful for:
  - Sharing results with colleagues
  - Loading results later without re-running t-SNE
  - Backup of your grouping work

### Save as Image
- Exports the current visualization as a PNG file
- Perfect for:
  - Reports and presentations
  - Documentation
  - Sharing on chat platforms

---

## üí° Tips and Best Practices

### Getting Quality Visualizations

1. **Choose appropriate perplexity**:
   - Small datasets (< 100 faces): perplexity = 5-15
   - Medium datasets (100-1000): perplexity = 30-50
   - Large datasets (> 1000): perplexity = 50+

2. **Run multiple times**:
   - t-SNE is non-deterministic (different each time)
   - Run 2-3 times and pick the best-looking result
   - Look for clear cluster separation

3. **Adjust point size for clarity**:
   - Larger datasets: Use smaller points
   - Fewer faces: Use larger points to see images clearly

### Understanding the Visualization

‚úÖ **What t-SNE preserves:**
- Local neighborhood structure
- Similar faces cluster together
- Relative distances between close faces

‚ùå **What t-SNE doesn't preserve:**
- Absolute distances (the scale is arbitrary)
- Angles between clusters
- Global structure perfectly

**Key insight:** If two faces are close in the visualization, they're similar. If they're far apart, they *might* be different (but not guaranteed).

### Working with Large Datasets

For datasets with 1000+ faces:
- Increase max iterations to 500-1000
- Use higher perplexity (40-50)
- Consider reducing point size
- Turn off "Show Labels" for cleaner view
- Use auto-clustering first, then refine manually

### Common Issues

**Problem: All faces in one blob**
- Solution: Lower the perplexity, increase iterations

**Problem: Faces too spread out**
- Solution: Increase perplexity, check early exaggeration

**Problem: Slow performance**
- Solution: Reduce max iterations, use fewer samples initially

**Problem: "Similar faces" don't look similar**
- Remember: Similarity is based on embeddings, not t-SNE positions
- The algorithm finds similar faces in the original high-dimensional space

---

## üîß Integration with Your Face Recognition System

### Step 1: Extract Face Embeddings

Using your face recognition model (examples):

**Python with FaceNet:**
```python
from keras_facenet import FaceNet
import numpy as np
import json

embedder = FaceNet()
embeddings = []
labels = []

for face_image in your_face_images:
    embedding = embedder.embeddings(face_image)
    embeddings.append(embedding.tolist())
    labels.append(face_name)

# Save to JSON
with open('face_data.json', 'w') as f:
    json.dump({
        'embeddings': embeddings,
        'labels': labels,
        'images': []  # Add base64 images if needed
    }, f)
```

**Python with face_recognition library:**
```python
import face_recognition
import json

embeddings = []
for image_path in image_paths:
    image = face_recognition.load_image_file(image_path)
    encoding = face_recognition.face_encodings(image)[0]
    embeddings.append(encoding.tolist())
```

### Step 2: Add Images (Optional)

**Convert images to base64:**
```python
import base64

def image_to_base64(image_path):
    with open(image_path, 'rb') as f:
        return 'data:image/jpeg;base64,' + base64.b64encode(f.read()).decode()

images = [image_to_base64(path) for path in image_paths]
```

### Step 3: Load in Visualizer

Simply drag-and-drop your generated JSON file into the visualizer!

---

## üéØ Use Cases

### 1. **Quality Control**
- Identify misclassified faces (outliers in clusters)
- Find duplicate entries
- Detect labeling errors

### 2. **Dataset Organization**
- Group faces by family, department, or category
- Create training sets for machine learning
- Balance datasets by identifying under-represented groups

### 3. **Face Search & Discovery**
- Find similar faces to a query face
- Explore unknown faces in large databases
- Identify potential matches across datasets

### 4. **Presentation & Communication**
- Visualize face recognition results for stakeholders
- Demonstrate clustering capabilities
- Share insights about face distributions

### 5. **Chat Applications**
- Display user faces organized by activity
- Show team member groupings
- Identify active user clusters

---

## üêõ Troubleshooting

### "Cannot read property 'length' of undefined"
- Check that your JSON has the correct structure
- Ensure `embeddings` field exists and is an array

### "Perplexity must be less than n_samples"
- You have too few samples for the perplexity value
- Reduce perplexity or add more face samples

### Visualization looks random/poor quality
- Try running multiple times (t-SNE is stochastic)
- Adjust perplexity (try different values)
- Increase max iterations
- Check that your embeddings are normalized

### Images not showing
- Verify image paths/URLs are accessible
- Check base64 encoding is correct
- Ensure images array matches embeddings array length

---

## üìö Additional Resources

### Understanding t-SNE
- [Original Paper](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)
- [How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)

### Face Recognition Models
- [FaceNet](https://github.com/davidsandberg/facenet)
- [face_recognition library](https://github.com/ageitgey/face_recognition)
- [ArcFace](https://github.com/deepinsight/insightface)

### Data Preparation
- Keep embeddings normalized (most models do this automatically)
- Ensure consistent preprocessing across all faces
- Remove corrupted or low-quality faces before embedding

---

## üí¨ Support & Feedback

Found a bug or have a feature request? This is a demonstration tool built on the t-SNE.js library.

**Tips for success:**
1. Start with the sample data to understand the interface
2. Test with a small subset of your data first (50-100 faces)
3. Experiment with different parameter values
4. Save your groups and export results frequently

Happy visualizing! üéâ

